{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "保持器_10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPH+6NINxSAF7ibQvxF+s0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nonna-nna/Nonna-nna/blob/Linear-guide/%E4%BF%9D%E6%8C%81%E5%99%A8_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#これはサンプルコード一覧です。"
      ],
      "metadata": {
        "id": "hMovKOmP6VoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ITブログ村\n",
        "\n",
        "https://it.blogmura.com/ranking/in?p_cid=11069769"
      ],
      "metadata": {
        "id": "6x60da0myrlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "過去記事一覧\n",
        "\n",
        "https://www.higashisalary.com/entry-list#toc10"
      ],
      "metadata": {
        "id": "mRk1oOWPx6iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マウスポインターを追いかけるコード\n",
        "\n",
        "https://www.higashisalary.com/entry/mouse-pos-to-txt"
      ],
      "metadata": {
        "id": "ZTDVejgxxwNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H74mr6hJt6CE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "file_name='sample.jpg'\n",
        "img=cv2.imread(file_name,cv2.IMREAD_GRAYSCALE)\n",
        "txt_file='pos_xy.txt'\n",
        "counter=0\n",
        "def mouse_move(event, x, y, flags, params):\n",
        "    global counter,txt\n",
        "    if event == cv2.EVENT_LBUTTONDOWN and counter==0:\n",
        "        counter=1\n",
        "        txt=open(txt_file, 'w')\n",
        "        txt.write('x'+\"\\t\"+'y'+\"\\n\")\n",
        "    elif event == cv2.EVENT_MOUSEMOVE and counter==1:\n",
        "        img2 = np.copy(img)\n",
        "        cv2.circle(img2,center=(x,y),radius=5,color=255,thickness=-1)\n",
        "        txt.write(str(x)+\"\\t\"+str(y)+\"\\n\")\n",
        "        xy_str='('+str(x)+','+str(y)+')'\n",
        "        cv2.putText(img2,xy_str,(30, 50),cv2.FONT_HERSHEY_PLAIN,2,255,2,cv2.LINE_AA)\n",
        "        cv2.imshow('window', img2)\n",
        "    elif event == cv2.EVENT_LBUTTONDOWN and counter==1:\n",
        "        txt.close()\n",
        "        counter=0\n",
        "cv2.imshow('window', img)\n",
        "cv2.setMouseCallback('window', mouse_move)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#重心履歴を算出\n",
        "\n",
        "https://www.higashisalary.com/entry/movie-object-moment"
      ],
      "metadata": {
        "id": "AeCBOKr2x3na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ライブラリインポート\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#動画ファイルの読み込み\n",
        "movie = cv2.VideoCapture('sample_movie.mp4')\n",
        "#フレーム数の取得\n",
        "nframe = int(movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "#重心計算関数\n",
        "def calc_moment(img):\n",
        "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img=255-img\n",
        "    h,w=img.shape[:2]\n",
        "    #二値化処理\n",
        "    thresh, img_thresh = cv2.threshold(img, 60, 255, cv2.THRESH_BINARY)\n",
        "    #輪郭抽出\n",
        "    contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    #塗りつぶし画像の作成\n",
        "    black_img=np.zeros((h,w),np.uint8)\n",
        "    cv2.drawContours(black_img, contours, 0, 255, -1)\n",
        "    #重心計算\n",
        "    M = cv2.moments(black_img, False)\n",
        "    x,y= int(M[\"m10\"]/M[\"m00\"]) , int(M[\"m01\"]/M[\"m00\"])\n",
        "    return x,y\n",
        "    \n",
        "#重心履歴の算出\n",
        "XYdata=[]\n",
        "for i in range(nframe):\n",
        "    ret, frame = movie.read()\n",
        "    x,y=calc_moment(frame)\n",
        "    XYdata.append([x,y])\n",
        "XYdata=np.array(XYdata)\n",
        "\n",
        "#重心履歴の可視化\n",
        "plt.scatter(XYdata[:,0],XYdata[:,1],color='red', linestyle='solid', linewidth = 2.0, label='moment')\n",
        "plt.xlabel('x',color='black',fontsize=14)\n",
        "plt.ylabel('y',color='black',fontsize=14)\n",
        "plt.savefig('moment.jpg', dpi=300)"
      ],
      "metadata": {
        "id": "p2759qi5yLAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "輝度の差分画像を取得\n",
        "\n",
        "https://www.higashisalary.com/entry/opencv-diff-pic#toc3"
      ],
      "metadata": {
        "id": "m5ZjZ8P6yHnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1フレームごとに画像を保存\n",
        "\n",
        "https://yasulab-pg.com/%E3%80%90python%E3%80%91%E5%8B%95%E7%94%BB%E3%81%8B%E3%82%89%EF%BC%91%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E3%81%94%E3%81%A8%E3%81%AE%E7%94%BB%E5%83%8F%E3%82%92%E4%BF%9D%E5%AD%98%E3%81%99%E3%82%8B/"
      ],
      "metadata": {
        "id": "XaX7H4lR38vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import sys\n",
        "\n",
        "video_path = R\"C:\\Users\\xxxxxxxxxx\\movie.avi\"\n",
        "\n",
        "# 動画ファイル読込\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    # 正常に読み込めたのかチェックする\n",
        "    # 読み込めたらTrue、失敗ならFalse\n",
        "    print(\"動画の読み込み失敗\")\n",
        "    sys.exit()\n",
        "\n",
        "# width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "# height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "# count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# print(\"width:{}, height:{}, count:{}, fps:{}\".format(width,height,count,fps))\n",
        "\n",
        "digit = len(str(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))))\n",
        "\n",
        "n= 0\n",
        "while True:\n",
        "    # read()でフレーム画像が読み込めたかを示すbool、フレーム画像の配列ndarrayのタプル\n",
        "    is_image,frame_img = cap.read()\n",
        "    if is_image:\n",
        "        # 画像を保存\n",
        "        cv2.imwrite(R\"C:\\Users\\xxxxxxxxxx\\\\\" + str(n).zfill(digit) + \".jpg\" , frame_img)\n",
        "    else:\n",
        "        # フレーム画像が読込なかったら終了\n",
        "        break\n",
        "    n += 1\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "vfLWBhv939Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "フレームをいろいろな方法で指定して切り取る\n",
        "\n",
        "https://note.nkmk.me/python-opencv-video-to-still-image/"
      ],
      "metadata": {
        "id": "L2AJ9hXw6Mrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "画像を座標空間に変換してみる\n",
        "\n",
        "https://dev.classmethod.jp/articles/convert-coords-screen-to-space/"
      ],
      "metadata": {
        "id": "KdAoqdJt6t7R"
      }
    }
  ]
}